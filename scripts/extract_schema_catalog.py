import os
import re
import sys
import json
import pymysql
import datetime
import concurrent.futures
from decimal import Decimal
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.config import settings
from app.core.llm import chat_completion
from app.core.prompts import TABLE_CARD_GOVERNANCE_PROMPT
from app.core.logger import logger

OUTPUT_FILE = settings.OUT_PATH
MAX_WORKERS = 5

# ==========================================
# ğŸ§¹ æ ¸å¿ƒæ¸…æ´—é€»è¾‘ (Quality Control)
# ==========================================
SYNONYM_BLACKLIST = re.compile(r"(è¡¨|è®°å½•|æ•°æ®|ä¿¡æ¯|ç®¡ç†|æœåŠ¡|åˆ—è¡¨|æ˜ç»†)$")


def clean_synonyms(synonyms: list, table_name: str) -> list:
    clean = []
    seen = set()
    for w in sorted(synonyms, key=len):
        w = w.strip()
        if not w or w == table_name: continue
        if len(w) > 10: continue
        if SYNONYM_BLACKLIST.search(w): continue
        if w not in seen:
            clean.append(w)
            seen.add(w)
    return clean[:5]


def extract_key_fields(columns_desc: str) -> str:
    keys = []
    lines = columns_desc.split('\n')
    for line in lines:
        match = re.search(r"- (\w+)", line)
        if not match: continue
        col_name = match.group(1).lower()
        if " [PK]" in line:
            keys.append(col_name)
        elif col_name.endswith("_id") or col_name.endswith("_code"):
            keys.append(col_name)
        elif "status" in col_name or "type" in col_name:
            keys.append(col_name)
        elif "amount" in col_name or "price" in col_name or "gmv" in col_name:
            keys.append(col_name)
    return ", ".join(keys[:8])


# ==========================================
# åŸºç¡€å·¥å…·
# ==========================================
def get_connection():
    return pymysql.connect(
        host=settings.MYSQL_HOST,
        port=settings.MYSQL_PORT,
        user=settings.MYSQL_USER,
        password=settings.MYSQL_PASSWORD,
        database=settings.MYSQL_CONNECT_DB,
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor
    )


class DateEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, (datetime.datetime, datetime.date)):
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        if isinstance(obj, Decimal):
            return float(obj)
        return super().default(obj)


def get_logical_name(table_name: str) -> str:
    name = re.sub(r'_\d{4}W\d{2,3}$', '', table_name, flags=re.IGNORECASE)
    name = re.sub(r'_\d{8}$', '', name)
    name = re.sub(r'_\d+$', '', name)
    return name


def get_all_tables_list(conn, db_name):
    """
    ğŸ”¥ ä¿®å¤1ï¼šæ”¹ç”¨ SHOW TABLE STATUSï¼Œè§£å†³ information_schema æŸ¥ä¸åˆ°è¡¨çš„é—®é¢˜
    """
    with conn.cursor() as cur:
        try:
            # å¼ºåˆ¶åˆ‡åº“
            cur.execute(f"USE {db_name}")
            cur.execute(f"SHOW TABLE STATUS")
            rows = cur.fetchall()

            result = []
            for r in rows:
                name = r.get('Name') or r.get('name')
                comment = r.get('Comment') or r.get('comment') or ""
                if name:
                    result.append({"table_name": name, "table_comment": comment})

            return result
        except Exception as e:
            print(f"   [WARN] SHOW TABLE STATUS failed: {e}")
            return []


def get_schema_info_str(conn, db_name, table_name):
    """
    ğŸ”¥ ä¿®å¤2ï¼šæ”¹ç”¨ SHOW FULL COLUMNSï¼Œè§£å†³ information_schema è§¦å‘ Proxy å†…éƒ¨ Bug (Error 30000)
    """
    with conn.cursor() as cur:
        try:
            # ShardingSphere å¯¹ SHOW FULL COLUMNS æ”¯æŒå¾ˆå¥½
            sql = f"SHOW FULL COLUMNS FROM `{table_name}` FROM `{db_name}`"
            cur.execute(sql)
            rows = cur.fetchall()

            col_desc_list = []
            for r in rows:
                # å…¼å®¹ä¸åŒé©±åŠ¨è¿”å›çš„å¤§å°å†™
                field = r.get('Field') or r.get('field')
                type_ = r.get('Type') or r.get('type')
                comment = r.get('Comment') or r.get('comment') or ""
                key_val = r.get('Key') or r.get('key')

                key_mark = " [PK]" if key_val == 'PRI' else ""
                col_desc_list.append(f"- {field} ({type_}){key_mark}: {comment}")

            return "\n".join(col_desc_list)
        except Exception as e:
            # å¦‚æœæŸå¼ è¡¨çœŸçš„æŸ¥ä¸åˆ°ï¼Œè¿”å›ç©ºï¼Œä¸è¦è®©æ•´ä¸ªè„šæœ¬å´©æ‰
            print(f"   [WARN] Failed to fetch schema for {table_name}: {e}")
            return f"Error fetching schema: {e}"


def get_samples_json(conn, db_name, table_name, limit=3):
    with conn.cursor() as cur:
        try:
            cur.execute(f"SELECT * FROM `{db_name}`.`{table_name}` LIMIT %s", (limit,))
            rows = cur.fetchall()
            if rows:
                rows = [{k.lower(): v for k, v in r.items()} for r in rows]
            return json.dumps(rows, cls=DateEncoder, ensure_ascii=False, indent=None)
        except Exception:
            return "[]"


# ==========================================
# ğŸ§µ çº¿ç¨‹å·¥ä½œå‡½æ•° (Worker)
# ==========================================
def process_single_logical_table(db, logical_name, physical_table, table_comment):
    conn = get_connection()
    try:
        # è·å–å…ƒæ•°æ® (ç°åœ¨ç”¨ SHOW FULL COLUMNSï¼Œç¨³å¾—ä¸€æ‰¹)
        columns_desc = get_schema_info_str(conn, db, physical_table)
        samples_json = get_samples_json(conn, db, physical_table, limit=3)

        key_fields = extract_key_fields(columns_desc)

        prompt = TABLE_CARD_GOVERNANCE_PROMPT.format(
            db=db,
            logical_table=logical_name,
            table=physical_table,
            domain="unknown",
            table_comment=table_comment,
            columns_desc=columns_desc,
            samples=samples_json
        )

        try:
            llm_resp = chat_completion(prompt)
            llm_data = json.loads(llm_resp)
        except Exception as e:
            # LLM å¶å°”å¤±è´¥ä¸å½±å“å¤§å±€
            llm_data = {"summary": f"{logical_name} æ•°æ®è¡¨", "synonyms": [], "risk_level": "normal",
                        "table_type": "fact"}

        raw_synonyms = llm_data.get('synonyms', [])
        cleaned_synonyms = clean_synonyms(raw_synonyms, logical_name)

        rich_text = (
            f"è¡¨å: {logical_name}\n"
            f"ä¸šåŠ¡åŸŸ: {llm_data.get('domain_suggestion', 'unknown')}\n"
            f"ç±»å‹: {llm_data.get('table_type', 'fact')}\n"
            f"å…³é”®å­—æ®µ: {key_fields}\n"
            f"ä¸šåŠ¡æè¿°: {llm_data.get('summary', '')}\n"
            f"åŒä¹‰è¯: {','.join(cleaned_synonyms)}\n"
            f"å­—æ®µç»“æ„:\n{columns_desc}\n"
            f"æ ·æœ¬æ•°æ®:\n{samples_json}"
        )

        card = {
            "identity": {
                "db": db,
                "logical_table": logical_name,
                "physical_table_example": physical_table,
                "domain": llm_data.get("domain_suggestion", "unknown")
            },
            "llm": {
                "risk_level": llm_data.get("risk_level", "normal"),
                "table_type": llm_data.get("table_type", "unknown"),
                "summary": llm_data.get("summary", ""),
                "synonyms": cleaned_synonyms
            },
            "text": rich_text,
            "last_update": datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        return card

    except Exception as e:
        logger.error(f"âŒ Error processing {logical_name}: {e}")
        return None
    finally:
        conn.close()


def main():
    logger.info(f"ğŸš€ Start ETL (Concurrency: {MAX_WORKERS})")
    conn = get_connection()
    target_dbs = settings.TARGET_DBS
    tasks = []

    for db in target_dbs:
        db = db.strip()
        if not db: continue

        logger.info(f"ğŸ“‚ Scanning DB: {db}")
        tables = get_all_tables_list(conn, db)

        seen_logical = set()
        for t in tables:
            p_name = t['table_name']
            l_name = get_logical_name(p_name)
            if l_name in seen_logical: continue
            seen_logical.add(l_name)
            tasks.append((db, l_name, p_name, t.get('table_comment', '')))

    conn.close()

    total_tasks = len(tasks)
    logger.info(f"ğŸ“‹ Total Logical Tables to Process: {total_tasks}")

    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_table = {
            executor.submit(process_single_logical_table, db, l_name, p_name, comment): l_name
            for (db, l_name, p_name, comment) in tasks
        }

        for future in tqdm(concurrent.futures.as_completed(future_to_table), total=total_tasks,
                           desc="Processing Tables"):
            try:
                card = future.result()
                if card:
                    results.append(card)
            except Exception as e:
                logger.error(f"Thread Error: {e}")

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for card in results:
            f.write(json.dumps(card, ensure_ascii=False) + "\n")

    logger.info(f"ğŸ‰ ETL Done! Saved {len(results)} tables to {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
import os
import sys
import json
from dotenv import load_dotenv
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
from sentence_transformers import SentenceTransformer

# 1. ç¯å¢ƒé…ç½®
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
load_dotenv(os.path.join(project_root, ".env"))

# 2. Milvus é…ç½®
MILVUS_HOST = os.getenv("MILVUS_HOST", "127.0.0.1")
MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")
COLLECTION_NAME = os.getenv("MILVUS_COLLECTION", "schema_catalog_v2")

# ğŸ”¥ å˜æ›´ç‚¹ 1: è¾“å…¥æ–‡ä»¶è·¯å¾„æ”¹ä¸º V2 äº§ç‰©
SOURCE_FILE = os.path.join(project_root, "data", "table_card_v1.jsonl")

EMBED_MODEL = os.getenv("EMBED_MODEL", "BAAI/bge-m3")
BATCH_SIZE = int(os.getenv("MILVUS_BATCH_SIZE", "64"))  # BGE-M3 æ¯”è¾ƒå¤§ï¼ŒBatch è°ƒå°ç‚¹ç¨³å¦¥
TEXT_MAX_LEN = int(os.getenv("MILVUS_TEXT_MAX_LEN", "8000"))


def init_milvus(dim: int) -> Collection:
    print(f"ğŸ”Œ Connecting to Milvus {MILVUS_HOST}:{MILVUS_PORT}...")
    connections.connect(alias="default", host=MILVUS_HOST, port=MILVUS_PORT)

    if utility.has_collection(COLLECTION_NAME):
        print(f"ğŸ—‘ï¸ Dropping existing collection: {COLLECTION_NAME}")
        utility.drop_collection(COLLECTION_NAME)

    print(f"ğŸ”¨ Creating collection: {COLLECTION_NAME}")

    # ğŸ”¥ å˜æ›´ç‚¹ 2: Schema é€‚é… TableCard ç»“æ„
    fields = [
        # ä¸»é”®
        FieldSchema(name="full_name", dtype=DataType.VARCHAR, max_length=256, is_primary=True),
        # å‘é‡
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dim),

        # åŸºç¡€å…ƒæ•°æ® (æ¥è‡ª identity)
        FieldSchema(name="db", dtype=DataType.VARCHAR, max_length=128),
        FieldSchema(name="logical_table", dtype=DataType.VARCHAR, max_length=128),
        FieldSchema(name="domain", dtype=DataType.VARCHAR, max_length=64),

        # æ²»ç†å…ƒæ•°æ® (æ¥è‡ª llm) -> ç”¨äºè¿‡æ»¤
        FieldSchema(name="risk_level", dtype=DataType.VARCHAR, max_length=32),  # normal/sensitive
        FieldSchema(name="table_type", dtype=DataType.VARCHAR, max_length=32),  # fact/dim

        # æ ¸å¿ƒç‰¹å¾ (æ¥è‡ª features) -> å­˜ä¸º JSON å­—ç¬¦ä¸²ï¼ŒGate å–å‡ºæ¥è½¬ dict ç”¨
        # è¿™æ ·æ¯”å­˜ feat_join_keys, feat_time_cols å¤šä¸ªå­—æ®µæ›´çµæ´»ï¼Œä»¥ååŠ ç‰¹å¾ä¸ç”¨æ”¹è¡¨ç»“æ„
        FieldSchema(name="features_json", dtype=DataType.VARCHAR, max_length=4096),

        # æ–‡æœ¬å†…å®¹ (æ¥è‡ª text)
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=max(8192, TEXT_MAX_LEN + 256)),
    ]

    schema = CollectionSchema(fields, description="TableCard V2: Governance Asset Catalog")
    col = Collection(COLLECTION_NAME, schema)

    # ç´¢å¼•
    index_params = {
        "index_type": "HNSW",
        "metric_type": "IP",  # å†…ç§¯ (é€‚ç”¨äºå½’ä¸€åŒ–åçš„ Cosine ç›¸ä¼¼åº¦)
        "params": {"M": 16, "efConstruction": 200},
    }
    col.create_index(field_name="embedding", index_params=index_params)
    return col


def insert_batch(col: Collection, model: SentenceTransformer, batch: list[dict]):
    texts = [x["raw_text_for_emb"] for x in batch]
    # å½’ä¸€åŒ–å‘é‡ï¼Œä½¿å¾— IP ç­‰ä»·äº Cosine
    embeddings = model.encode(texts, normalize_embeddings=True)

    col.insert([
        [x["full_name"] for x in batch],
        embeddings.tolist(),
        [x["db"] for x in batch],
        [x["logical_table"] for x in batch],
        [x["domain"] for x in batch],
        [x["risk_level"] for x in batch],
        [x["table_type"] for x in batch],
        [x["features_json"] for x in batch],
        [x["text"] for x in batch],
    ])


def main():
    if not os.path.exists(SOURCE_FILE):
        print(f"âŒ File not found: {SOURCE_FILE}. Please run extract_schema_catalog_v2.py first.")
        return

    print(f"ğŸ§  Loading embedding model: {EMBED_MODEL}...")
    try:
        model = SentenceTransformer(EMBED_MODEL)
    except Exception as e:
        print(f"âŒ Model load failed: {e}")
        print("Try: pip install sentence-transformers")
        return

    # æµ‹ç®—ç»´åº¦
    test_emb = model.encode(["test"], normalize_embeddings=True)
    dim = int(test_emb.shape[1])
    print(f"ğŸ“ Vector dimension: {dim}")

    col = init_milvus(dim)

    inserted = 0
    batch = []

    print(f"ğŸš€ Processing data from {SOURCE_FILE}...")
    with open(SOURCE_FILE, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line: continue

            try:
                card = json.loads(line)
            except:
                continue

            # ğŸ”¥ å˜æ›´ç‚¹ 3: è§£æåµŒå¥—ç»“æ„ (TableCard)
            ident = card.get("identity", {})
            llm = card.get("llm", {})
            features = card.get("features", {})

            # æ„é€ ä¸»é”®
            full_name = f"{ident.get('db')}.{ident.get('logical_table')}"

            # æˆªæ–­æ–‡æœ¬é˜²æ­¢è¶…é•¿
            raw_text = card.get("text", "")
            safe_text = raw_text[:TEXT_MAX_LEN]

            entry = {
                "full_name": full_name,
                "db": ident.get("db", ""),
                "logical_table": ident.get("logical_table", ""),
                "domain": ident.get("domain", "unknown"),

                # æ–°å­—æ®µ
                "risk_level": llm.get("risk_level", "normal"),
                "table_type": llm.get("table_type", "unknown"),
                "features_json": json.dumps(features, ensure_ascii=False),  # å­˜æ•´ä¸ªç‰¹å¾åŒ…

                "text": safe_text,
                "raw_text_for_emb": raw_text  # å‘é‡è®¡ç®—ç”¨å…¨é‡
            }
            batch.append(entry)

            if len(batch) >= BATCH_SIZE:
                insert_batch(col, model, batch)
                inserted += len(batch)
                print(f"  âœ… Inserted: {inserted}")
                batch = []

    if batch:
        insert_batch(col, model, batch)
        inserted += len(batch)
        print(f"  âœ… Inserted: {inserted}")

    col.flush()
    # col.load() # å†™å…¥å®Œä¸éœ€è¦ç«‹å³ loadï¼Œç­‰æŸ¥è¯¢æ—¶å† load

    print(f"ğŸ‰ All Done! Total {col.num_entities} entities indexed in '{COLLECTION_NAME}'.")


if __name__ == "__main__":
    main()
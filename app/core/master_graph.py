import os
from typing import TypedDict, Literal, List
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from app.core.config import settings
from app.core.prompts import ROUTER_PROMPT
from app.core.mysql_saver import AsyncMySQLSaver
from app.core.agent_graph import app as query_agent_app

# ==========================================
# ğŸ”¥ è¡¥å›ä¸¢å¤±çš„ DB é…ç½® (main.py éœ€è¦ç”¨åˆ°)
# ==========================================
DB_CONFIG = {
    "host": settings.MYSQL_HOST,
    "port": 3306,  # å¼ºåˆ¶èµ°ç‰©ç†ç«¯å£ï¼Œé¿å¼€ Proxy
    "user": settings.MYSQL_USER,
    "password": settings.MYSQL_PASSWORD,
    "db": "dbops_memory",
    "autocommit": True
}

# --- åˆå§‹åŒ– LLM ---
llm = ChatOpenAI(
    model=settings.LLM_MODEL,
    temperature=0,
    api_key=settings.LLM_API_KEY,
    base_url=settings.LLM_BASE_URL
)


# --- å®šä¹‰ Master çŠ¶æ€ ---
class MasterState(TypedDict):
    question: str
    intent: str
    final_answer: str
    trace_id: str
    history: List[str]  # ä¸»å›¾è¿™é‡Œå­˜å­—ç¬¦ä¸²åˆ—è¡¨æ²¡é—®é¢˜


# --- å®šä¹‰è·¯ç”±è¾“å‡º ---
class RouterOutput(BaseModel):
    intent: Literal["DATA_QUERY", "KNOWLEDGE_SEARCH", "CHAT"]


# ==========================================
# Nodes
# ==========================================
def router_node(state: MasterState):
    print(f"ğŸš¦ [Master] Routing query: {state['question']}")
    current_history = state.get("history", [])

    # æ„é€  Prompt
    prompt = ROUTER_PROMPT.format(question=state["question"])

    # è°ƒç”¨ LLM å†³ç­–
    try:
        res = llm.with_structured_output(RouterOutput).invoke(prompt)
        intent = res.intent
    except Exception as e:
        print(f"âš ï¸ Router LLM failed: {e}, fallback to CHAT")
        intent = "CHAT"

    print(f"    -> Route to: {intent}")
    return {"intent": intent, "history": current_history}


async def search_agent_node(state: MasterState):
    print("ğŸŒ [Search Agent] Searching knowledge...")
    # ç®€å•æ¨¡æ‹Ÿæœç´¢
    res = await llm.ainvoke(f"è¯·ç®€è¦å›ç­”è¿™ä¸ªæŠ€æœ¯é—®é¢˜: {state['question']}")
    # æ›´æ–°å†å²ï¼šç»Ÿä¸€è½¬ä¸ºå­—ç¬¦ä¸²æ ¼å¼
    new_history = state.get("history", []) + [f"User: {state['question']}", f"AI: {res.content}"]
    return {"final_answer": res.content, "history": new_history}


async def chat_node(state: MasterState):
    # ç®€å•é—²èŠ
    res = await llm.ainvoke(f"è¯·ç”¨äº²åˆ‡çš„è¯­æ°”å›å¤ç”¨æˆ·: {state['question']}")
    new_history = state.get("history", []) + [f"User: {state['question']}", f"AI: {res.content}"]
    return {"final_answer": res.content, "history": new_history}


async def call_query_agent(state: MasterState):
    print("ğŸ“Š [Query Agent] Activated.")
    global_history = state.get("history", [])
    recent_history = global_history[-6:]

    inputs = {
        "question": state["question"],
        "trace_id": state.get("trace_id"),
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼škey å¿…é¡»æ˜¯ "history"ï¼Œå¯¹åº” AgentState å®šä¹‰ ğŸ”¥ğŸ”¥ğŸ”¥
        # åŸæ¥å†™çš„æ˜¯ "chat_history"ï¼Œå¯¼è‡´å­ Agent æ‹¿ä¸åˆ°å†å²
        "history": recent_history
    }

    # è°ƒç”¨å­å›¾
    result_state = await query_agent_app.ainvoke(inputs)

    # è§£æç»“æœ
    final_ans = ""
    if result_state.get("generated_sql"):
        # ä¼˜å…ˆå±•ç¤º SQL
        final_ans = f"SQL_RESULT:{result_state['generated_sql']}"
        ai_msg = f"Generated SQL: {result_state['generated_sql']}"
    elif result_state.get("final_answer"):
        # å¦‚æœæœ‰å…œåº•å›å¤ (æ¯”å¦‚ Fallback)
        final_ans = result_state["final_answer"]
        ai_msg = final_ans
    else:
        final_ans = "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„æŸ¥è¯¢è¯­å¥ã€‚"
        ai_msg = "Failed to generate SQL"

    # æ›´æ–°ä¸»å›¾å†å²
    new_history = global_history + [f"User: {state['question']}", f"AI: {ai_msg}"]
    return {"final_answer": final_ans, "history": new_history}


# ==========================================
# Graph Definition
# ==========================================
workflow = StateGraph(MasterState)
workflow.add_node("router", router_node)
workflow.add_node("search_agent", search_agent_node)
workflow.add_node("chat_agent", chat_node)
workflow.add_node("data_query_agent", call_query_agent)

workflow.set_entry_point("router")


def route_logic(state):
    return state["intent"]


workflow.add_conditional_edges(
    "router",
    route_logic,
    {
        "DATA_QUERY": "data_query_agent",
        "KNOWLEDGE_SEARCH": "search_agent",
        "CHAT": "chat_agent"
    }
)
workflow.add_edge("search_agent", END)
workflow.add_edge("chat_agent", END)
workflow.add_edge("data_query_agent", END)

# ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ 1: å…¨å±€å˜é‡åˆå§‹ä¸º None (Lazy Init)
master_app = None


# ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ 2: çœŸæ­£çš„åˆå§‹åŒ–é€»è¾‘æ”¾åœ¨å‡½æ•°é‡Œ
def init_master_app(pool):
    """
    ç”± main.py è°ƒç”¨ï¼Œæ³¨å…¥æ•°æ®åº“è¿æ¥æ± ï¼Œå¯ç”¨æŒä¹…åŒ–è®°å¿†
    """
    global master_app
    print("ğŸ§  [Master] Injecting MySQL Memory Saver (Lazy Init)...")

    # 1. å®ä¾‹åŒ– Saver
    checkpointer = AsyncMySQLSaver(pool)

    # 2. ç¼–è¯‘ Graph
    master_app = workflow.compile(checkpointer=checkpointer)
    return master_app
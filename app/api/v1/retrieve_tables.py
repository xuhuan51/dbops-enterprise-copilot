import datetime
import threading
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any, Optional

from fastapi import APIRouter
from pydantic import BaseModel
from pymilvus import Collection, connections, utility
from sentence_transformers import SentenceTransformer, CrossEncoder

from app.core.config import settings
from app.core.logger import logger
from app.modules.sql.executor import append_event  # è®°å¾—å¼•å…¥æ—¥å¿—è®°å½•

router = APIRouter(tags=["RAG"])

# =========================
# Config
# =========================
MILVUS_HOST = settings.MILVUS_HOST
MILVUS_PORT = settings.MILVUS_PORT
COLLECTION_NAME = settings.MILVUS_COLLECTION

EMBED_MODEL_NAME = settings.EMBED_MODEL
RERANK_MODEL_NAME = settings.RERANK_MODEL

# Recall / Rerank / Final defaults
DEFAULT_TOP_K_RECALL = int(getattr(settings, "TOP_K_RECALL", 100))
DEFAULT_TOP_K_RERANK = int(getattr(settings, "TOP_K_RERANK", 20))
DEFAULT_TOP_K_FINAL = int(getattr(settings, "TOP_K_FINAL", 5))

RERANK_THRESHOLD = float(getattr(settings, "RERANK_THRESHOLD", 0.01))
SENSITIVE_KEYWORDS = ["å·¥èµ„", "è–ªæ°´", "åº•è–ª", "å¯†ç ", "å¯†é’¥", "token", "salary", "password"]

# =========================
# Singletons + Locks
# =========================
_embed_model: Optional[SentenceTransformer] = None
_rerank_model: Optional[CrossEncoder] = None
_collection_loaded = False

_model_lock = threading.Lock()
_milvus_lock = threading.Lock()

# ä¸“é—¨ç”¨äºè·‘æ¨¡å‹æ¨ç†çš„çº¿ç¨‹æ± 
_executor = ThreadPoolExecutor(max_workers=3)


# =========================
# Core Logic Functions
# =========================

def get_embed_model() -> SentenceTransformer:
    global _embed_model
    if _embed_model is None:
        with _model_lock:
            if _embed_model is None:
                logger.info(f"ğŸ§  Loading Embedding Model: {EMBED_MODEL_NAME}...")
                _embed_model = SentenceTransformer(EMBED_MODEL_NAME)
    return _embed_model


def get_rerank_model() -> Optional[CrossEncoder]:
    global _rerank_model
    if _rerank_model is None:
        with _model_lock:
            if _rerank_model is None:
                logger.info(f"ğŸ§  Loading Rerank Model: {RERANK_MODEL_NAME}...")
                try:
                    _rerank_model = CrossEncoder(RERANK_MODEL_NAME)
                except Exception as e:
                    logger.warning(f"âš ï¸ Rerank model load failed: {e}. Fallback to None.")
                    _rerank_model = None
    return _rerank_model


def ensure_milvus_connection() -> bool:
    global _collection_loaded
    with _milvus_lock:
        try:
            if not connections.has_connection("default"):
                connections.connect(alias="default", host=MILVUS_HOST, port=MILVUS_PORT)
        except Exception as e:
            logger.error(f"âŒ Milvus Connect Error: {e}")
            return False

        if not _collection_loaded:
            try:
                if not utility.has_collection(COLLECTION_NAME):
                    logger.error(f"âŒ Collection '{COLLECTION_NAME}' not found! Please run ETL first.")
                    return False
                logger.info(f"ğŸ”„ Loading collection '{COLLECTION_NAME}' into memory...")
                Collection(COLLECTION_NAME).load()
                _collection_loaded = True
                logger.info(f"âœ… Collection '{COLLECTION_NAME}' loaded.")
            except Exception as e:
                logger.error(f"âŒ Collection load failed: {e}", exc_info=True)
                return False
    return True


# è¾…åŠ©å‡½æ•°ï¼šåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ Embedding (CPUå¯†é›†)
def _run_embedding(model, text):
    return model.encode([text], normalize_embeddings=True)[0].tolist()


# è¾…åŠ©å‡½æ•°ï¼šåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ Rerank (CPUå¯†é›†)
def _run_rerank(model, pairs):
    return model.predict(pairs, batch_size=32, show_progress_bar=False)


# ğŸ”¥ æ”¹ä¸º async def
async def retrieve_tables(query: str, topk: int = 5, trace_id: str = "N/A") -> List[Dict[str, Any]]:
    # 1. ç¡¬è§„åˆ™è¿‡æ»¤
    for kw in SENSITIVE_KEYWORDS:
        if kw in query:
            logger.warning(f"ğŸ›‘ [Security] Query contains sensitive keyword '{kw}'. Blocked.")
            return []

    # è°ƒç”¨å¼‚æ­¥çš„é«˜çº§æ£€ç´¢
    return await retrieve_tables_advanced(
        query=query,
        top_k_recall=max(topk * 10, 50),
        top_k_rerank=DEFAULT_TOP_K_RERANK,
        top_k_final=topk,
        trace_id=trace_id # ğŸ”¥ è®°å¾—æŠŠ trace_id ä¼ ç»™ä¸‹é¢
    )


# ğŸ”¥ æ”¹ä¸º async def
async def retrieve_tables_advanced(
        query: str,
        top_k_recall: int = DEFAULT_TOP_K_RECALL,
        top_k_rerank: int = DEFAULT_TOP_K_RERANK,
        top_k_final: int = DEFAULT_TOP_K_FINAL,
        trace_id: str = "N/A"  # å»ºè®®åŠ ä¸Š trace_id å‚æ•°
) -> List[Dict[str, Any]]:
    if not query:
        return []

    # Milvus è¿æ¥æ£€æŸ¥ (è¿™ä¸€æ­¥å¾ˆå¿«ï¼Œå¯ä»¥åŒæ­¥)
    if not ensure_milvus_connection():
        return []

    t0 = time.perf_counter()
    logger.info(f"ğŸ” [Retrieve] Start searching for: '{query}'")

    # -------- 1) Recall (Milvus) --------
    try:
        loop = asyncio.get_running_loop()
        col = Collection(COLLECTION_NAME)
        model = get_embed_model()

        # ğŸ”¥ å¼‚æ­¥æ‰§è¡Œ Embedding (é˜²æ­¢é˜»å¡ä¸»çº¿ç¨‹)
        embed_t0 = time.perf_counter()
        query_vec = await loop.run_in_executor(_executor, _run_embedding, model, query)
        embed_ms = (time.perf_counter() - embed_t0) * 1000.0

        # Milvus æœç´¢ (IOæ“ä½œï¼Œç›®å‰ pymilvus åªæœ‰åŒæ­¥ç‰ˆï¼Œæš‚ä¸”è¿™æ ·è·‘ï¼Œæˆ–è€…ä¹Ÿæ”¾ executor)
        search_params = {"metric_type": "IP", "params": {"nprobe": 10}}
        milvus_t0 = time.perf_counter()

        # å°† Milvus æœç´¢æ”¾å…¥çº¿ç¨‹æ± 
        def _search_milvus():
            return col.search(
                data=[query_vec],
                anns_field="embedding",
                param=search_params,
                limit=top_k_recall,
                output_fields=["db", "logical_table", "text"],
            )

        res = await loop.run_in_executor(_executor, _search_milvus)
        milvus_ms = (time.perf_counter() - milvus_t0) * 1000.0

        candidates: List[Dict[str, Any]] = []
        seen = set()

        for hits in res:
            for hit in hits:
                entity = hit.entity
                full_name = f"{entity.get('db')}.{entity.get('logical_table')}"
                if full_name in seen:
                    continue
                seen.add(full_name)
                candidates.append(
                    {
                        "score": float(hit.score),
                        "db": entity.get("db"),
                        "logical_table": entity.get("logical_table"),
                        "full_name": full_name,
                        "text": entity.get("text") or "",
                    }
                )

        if not candidates:
            logger.info("âœ… [Retrieve] No candidates from Milvus.")
            return []

        candidates.sort(key=lambda x: x["score"], reverse=True)

    except Exception as e:
        logger.error(f"âŒ Milvus Search Failed: {e}", exc_info=True)
        return []

    # -------- 2) Rerank --------
    reranker = get_rerank_model()
    candidates_final = candidates

    if reranker is not None:
        rerank_pool = candidates[: max(1, min(top_k_rerank, len(candidates)))]
        try:
            rerank_t0 = time.perf_counter()
            pairs = [[query[:256], c["text"][:512]] for c in rerank_pool]

            # ğŸ”¥ å¼‚æ­¥æ‰§è¡Œ Rerank æ¨ç† (CPUå¯†é›†)
            scores = await loop.run_in_executor(_executor, _run_rerank, reranker, pairs)
            rerank_ms = (time.perf_counter() - rerank_t0) * 1000.0

            for i, c in enumerate(rerank_pool):
                c["rerank_score"] = float(scores[i])

            rerank_pool.sort(key=lambda x: x["rerank_score"], reverse=True)

            # Cutoff
            top1 = rerank_pool[0].get("rerank_score", -999.0)
            if top1 < RERANK_THRESHOLD:
                logger.info(f"ğŸ›‘ [Retrieve] Cutoff: top1 {top1:.3f} < threshold {RERANK_THRESHOLD}. Return [].")
                # è¿™é‡Œä¹Ÿå¯ä»¥è®°ä¸€æ¡ cutoff æ—¥å¿—
                return []

            candidates_final = rerank_pool

        except Exception as e:
            logger.error(f"âš ï¸ [Rerank Failed] {e}. Fallback to vector score.", exc_info=True)

    # -------- 4) Final output --------
    final_results = candidates_final[: max(0, min(top_k_final, len(candidates_final)))]
    total_ms = (time.perf_counter() - t0) * 1000.0

    # 1. æå–è¡¨ååˆ—è¡¨ (æ–¹ä¾¿æŸ¥çœ‹)
    table_names = [t["logical_table"] for t in final_results]

    # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šç›´æ¥æŠŠè¡¨åæ‰“å°åœ¨æ§åˆ¶å°ï¼
    logger.info(f"âœ… [Retrieve] Found {len(final_results)} tables: {table_names} | ms={total_ms:.0f}")

    # 2. å†™å…¥å®¡è®¡æ—¥å¿— (events.jsonl)
    try:
        append_event({
            "trace_id": trace_id,
            "user_id": "system_retriever",
            "route": "RETRIEVE",
            "sql": query,
            "latency_ms": int(total_ms),
            "truncated": False,
            "error": None,
            "result_summary": table_names,  # è¿™é‡Œä¹Ÿä¼šè®°å½•
            "ts_iso": datetime.utcnow().isoformat(),
        })
    except Exception:
        pass

    return final_results


# =========================
# API Endpoints
# =========================

class RetrieveRequest(BaseModel):
    query: str
    top_k: int = 5


# ğŸ”¥ è·¯ç”±å‡½æ•°ä¹Ÿè¦æ”¹æˆ async def
@router.post("/retrieve")
async def api_retrieve_tables(req: RetrieveRequest):
    results = await retrieve_tables(req.query, topk=req.top_k)
    return {
        "query": req.query,
        "count": len(results),
        "results": results
    }
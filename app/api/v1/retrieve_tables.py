import json
import re
import time
import uuid
from typing import List, Dict, Any, Optional, Set

from fastapi import APIRouter
from pydantic import BaseModel, Field

# å¼•å…¥æ ¸å¿ƒç»„ä»¶
from app.core.llm import chat_completion
from app.core.prompts import RETRIEVAL_JUDGE_TEMPLATE
from app.core.domain_config import get_relevant_rules, ECOMMERCE_EXAMPLES
from app.modules.retrieval.schema_retriever import retrieve_tables

router = APIRouter(prefix="/api/v1", tags=["retrieve"])

# =========================
# 0. é…ç½®å‚æ•°
# =========================
PREFETCH_K = 500  # å‘é‡æ£€ç´¢å¬å›æ•°é‡
GATE_CANDIDATE_K = 20  # è¿›å…¥é—¨ç¦æ£€æŸ¥çš„å€™é€‰è¡¨æ•°é‡
FINAL_TOP_K = 5  # æœ€ç»ˆè¿”å›æ•°é‡

MIN_SCORE_THRESHOLD = 0.45
MAX_HOPS = 1  # æœ€å¤§é‡è¯•æ¬¡æ•°


# =========================
# 1. æ ¸å¿ƒæ•°æ®ç»“æ„ (Pydantic)
# =========================

class Filters(BaseModel):
    allowed_dbs: Optional[List[str]] = None
    domain: Optional[str] = None


class RetrieveReq(BaseModel):
    user_id: str
    query: str
    topk: int = FINAL_TOP_K
    filters: Optional[Filters] = None


# âœ… æ–°å¢ï¼šLLM æå–çš„éœ€æ±‚ç»“æ„
class QueryNeeds(BaseModel):
    intent: str = Field(..., description="data_query | non_data | sensitive")
    must_have: Dict[str, List[str]] = Field(...,
                                            description="å¿…é¡»å…·å¤‡çš„èƒ½åŠ›ï¼Œå¦‚ {'entity': ['user'], 'dimension': ['time']}")
    search_keywords: List[str] = Field(default=[], description="ç”¨äºé‡æœçš„å…³é”®è¯")


# =========================
# 2. æ ¸å¿ƒç»„ä»¶ï¼šNeeds Extraction (éœ€æ±‚æå–)
# =========================
def extract_query_needs(query: str) -> QueryNeeds:
    """
    è®© LLM åˆ†æç”¨æˆ·Queryï¼Œæå–ç¡¬æ€§éœ€æ±‚ (Must Have)ã€‚
    ä¸æ¶‰åŠå…·ä½“è¡¨åï¼Œåªæ¶‰åŠä¸šåŠ¡èƒ½åŠ›ã€‚
    """
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æå¸ˆã€‚è¯·åˆ†æç”¨æˆ·é—®é¢˜ï¼Œæå–æŸ¥è¯¢æ‰€éœ€çš„ã€æ ¸å¿ƒæ•°æ®èƒ½åŠ›ã€‘ã€‚

User Query: "{query}"

è¯·è¾“å‡º JSONï¼ŒåŒ…å«ï¼š
1. intent: "data_query" (æ­£å¸¸æŸ¥è¯¢) | "non_data" (é—²èŠ/å†™è¯—) | "sensitive" (æŸ¥å·¥èµ„/å¯†ç )
2. must_have: å¿…é¡»å…·å¤‡çš„å­—æ®µèƒ½åŠ›ï¼Œä»ä»¥ä¸‹ç±»åˆ«ä¸­é€‰ï¼š
   - "entity": éœ€è¦çš„ä¸»ä½“ (user, order, sku, supplier, activity...)
   - "dimension": éœ€è¦çš„è¿‡æ»¤/åˆ†ç»„ç»´åº¦ (time, region, channel, status...)
   - "metric": éœ€è¦çš„ç»Ÿè®¡æŒ‡æ ‡ (amount, qty, count, duration...)
   - "join": éœ€è¦è·¨è¡¨å…³è” (join)
3. search_keywords: å¦‚æœå½“å‰æ£€ç´¢å¤±è´¥ï¼Œä½ å»ºè®®ç”¨ä»€ä¹ˆå…³é”®è¯å»é‡æœï¼Ÿ(æä¾›3-5ä¸ªåŒä¹‰è¯/ä¸šåŠ¡è¯)

ç¤ºä¾‹ï¼š
Query: "ç»Ÿè®¡ä¸Šä¸ªæœˆåŒ—äº¬ç”¨æˆ·çš„æ³¨å†Œé‡"
JSON:
{{
    "intent": "data_query",
    "must_have": {{
        "entity": ["user"],
        "dimension": ["time", "region"],
        "metric": ["count"]
    }},
    "search_keywords": ["ç”¨æˆ·åŸºç¡€ä¿¡æ¯", "æ³¨å†Œæ—¶é—´", "create_time", "åœ°åŒº"]
}}
"""
    try:
        raw = chat_completion(prompt)
        # ç®€å•çš„ JSON æå–
        json_str = re.search(r"\{[\s\S]*\}", raw).group(0)
        data = json.loads(json_str)
        return QueryNeeds(**data)
    except Exception as e:
        print(f"âš ï¸ Needs Extraction Failed: {e}")
        # å…œåº•ï¼šå‡è®¾æ˜¯æ™®é€šæŸ¥è¯¢ï¼Œæ— å¼ºåˆ¶çº¦æŸ
        return QueryNeeds(intent="data_query", must_have={}, search_keywords=[])


# =========================
# 3. æ ¸å¿ƒç»„ä»¶ï¼šCapability Gate (ç¡¬é—¨ç¦)
# =========================
def check_capabilities(needs: QueryNeeds, candidates: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ä»£ç é€»è¾‘é—¨ç¦ï¼šæ£€æŸ¥å€™é€‰è¡¨æ˜¯å¦è¦†ç›–äº† must_have çš„èƒ½åŠ›ã€‚
    è¿”å›: {"pass": bool, "missing": str}
    """
    # 1. ç†”æ–­æ£€æŸ¥
    if needs.intent in ["non_data", "sensitive"]:
        return {"pass": False, "action": "ASK_USER", "reason": f"Intent is {needs.intent}"}

    if not candidates:
        return {"pass": False, "action": "REWRITE", "reason": "No candidates found"}

    # 2. æ”¶é›†æ‰€æœ‰å€™é€‰è¡¨çš„èƒ½åŠ›å¹¶é›†
    # è¿™é‡Œçš„ features æ˜¯ä» Milvus è¯»å‡ºæ¥çš„ feat_xxx_cols JSON å­—ç¬¦ä¸²è§£æåçš„åˆ—è¡¨
    all_caps = {
        "entity": set(),  # ä» domain æ¨æ–­ï¼Œæˆ– features é‡Œæœ‰ uid/oid
        "dimension": set(),
        "metric": set()
    }

    for c in candidates:
        # è§£æ features (å‡è®¾å·²è½¬ä¸º dict/list)
        feats = c.get("features", {})

        # Time Dimension
        if feats.get("time_cols"):
            all_caps["dimension"].add("time")

        # Region/Status ç­‰å…¶ä»–ç»´åº¦ (å¯ä»¥ä» columns é‡Œç®€å•çš„æ­£åˆ™åˆ¤æ–­ï¼Œæˆ–ç¦»çº¿å·²æ‰“æ ‡)
        # è¿™é‡Œç®€åŒ–ï¼šå¦‚æœæœ‰ domain=userï¼Œé»˜è®¤æœ‰ user entity
        domain = c.get("domain", "")
        if domain == "user": all_caps["entity"].add("user")
        if domain == "trade": all_caps["entity"].add("order")
        if domain == "scm": all_caps["entity"].add("sku")

        # Metrics
        if feats.get("metric_cols"):
            all_caps["metric"].add("metric")  # åªè¦æœ‰æŒ‡æ ‡åˆ—å°±ç®—æœ‰ metric èƒ½åŠ›
            # ä¹Ÿå¯ä»¥æ›´ç»†ï¼šif "amount" in feats['metric_cols']: ...

    # 3. å¯¹ç…§æ£€æŸ¥
    missing = []

    # æ£€æŸ¥ç»´åº¦ (Time)
    if "time" in needs.must_have.get("dimension", []) and "time" not in all_caps["dimension"]:
        missing.append("ç¼ºå°‘[æ—¶é—´]ç»´åº¦å­—æ®µ")

    # æ£€æŸ¥å®ä½“ (User) - è¿™æ˜¯ä¸€ä¸ªå¼ºæ ¡éªŒç¤ºä¾‹
    if "user" in needs.must_have.get("entity", []) and "user" not in all_caps["entity"]:
        missing.append("ç¼ºå°‘[ç”¨æˆ·]ç›¸å…³è¡¨")

    # 4. åˆ¤å®š
    if missing:
        return {
            "pass": False,
            "action": "REWRITE",
            "reason": f"Gateæ‹¦æˆª: {','.join(missing)}",
            "missing_caps": missing
        }

    return {"pass": True, "action": "PASS"}


# =========================
# 4. è¾…åŠ©å‡½æ•° (èšåˆ & æœç´¢)
# =========================
def _safe_json_load(s):
    if isinstance(s, list): return s
    try:
        return json.loads(s)
    except:
        return []


def aggregate_shards_and_parse(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    1. åˆ†è¡¨èšåˆ (é€»è¾‘åŒå‰)
    2. è§£æ Milvus å­˜çš„ JSON å­—ç¬¦ä¸² (feat_time_cols) ä¸ºåˆ—è¡¨
    """
    # ... (åˆ†è¡¨èšåˆé€»è¾‘ä¸ä¹‹å‰ç›¸åŒï¼Œç•¥å¾®ç®€åŒ–å±•ç¤º) ...
    # å‡è®¾ items å·²ç»æ˜¯ retrieve_tables è¿”å›çš„ raw data

    # è¿™é‡Œé‡ç‚¹æ˜¯è§£æ features
    for it in items:
        # Milvus é‡Œçš„ feat_time_cols æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬å› list
        it["features"] = {
            "time_cols": _safe_json_load(it.get("feat_time_cols", "[]")),
            "metric_cols": _safe_json_load(it.get("feat_metric_cols", "[]")),
            "join_keys": _safe_json_load(it.get("feat_join_keys", "[]"))
        }
    return items  # è¿™é‡Œåº”ä¿ç•™ aggregate_shards çš„å»é‡é€»è¾‘


def search_by_keywords(keywords: List[str]) -> List[Dict[str, Any]]:
    # è°ƒç”¨åº•å±‚çš„ retrieve_tables
    # å®é™…åº”åŒ…å«å»é‡é€»è¾‘
    results = []
    for kw in keywords:
        res = retrieve_tables(kw, topk=50)  # æ‰©å¤§æœç´¢
        if res: results.extend(res)
    return aggregate_shards_and_parse(results)


# =========================
# 5. åŸæœ‰çš„ Judge (ç”¨äº Gate é€šè¿‡åçš„ç²¾é€‰)
# =========================
def llm_judge_final(query: str, candidates: List[Dict[str, Any]]) -> Dict:
    # ... (ä»£ç ä¸ä¹‹å‰ä¸€è‡´ï¼šåŠ¨æ€ prompt + è§„åˆ™) ...
    # ç•¥å†™ï¼Œç›´æ¥è°ƒç”¨ä¹‹å‰çš„é€»è¾‘
    return {"status": "PASS", "selected_tables": [c['logical_table'] for c in candidates[:3]]}


# =========================
# 6. ä¸» API å…¥å£
# =========================
@router.post("/retrieve_tables_gate")
def retrieve_tables_with_gate(req: RetrieveReq):
    trace_id = str(uuid.uuid4())
    t0 = time.time()

    # --- Step 1: åˆå§‹æ£€ç´¢ (Vector Recall) ---
    raw_1 = retrieve_tables(req.query, topk=PREFETCH_K) or []
    # èšåˆåˆ†è¡¨ & è§£æ features JSON
    candidates_pool = aggregate_shards_and_parse(raw_1)

    # æˆªå– Top K è¿›å…¥é—¨ç¦
    candidates_gate = candidates_pool[:GATE_CANDIDATE_K]

    # --- Step 2: éœ€æ±‚æå– (LLM) ---
    needs = extract_query_needs(req.query)

    # --- Step 3: Capability Gate (Python Logic) ---
    gate_result = check_capabilities(needs, candidates_gate)

    gate_action = gate_result["action"]
    final_pool = candidates_gate

    # --- Step 4: å¤„ç† Gate ç»“æœ ---
    if gate_action == "ASK_USER":
        return {
            "success": True,
            "agent_decision": {"need_clarify": True, "reason": gate_result["reason"]}
        }

    elif gate_action == "REWRITE":
        # ğŸ”´ è§¦å‘é‡æœï¼
        print(f"ğŸ”„ Gate blocked: {gate_result['reason']}. Rewriting...")

        # ä½¿ç”¨ LLM ç”Ÿæˆçš„ keywords é‡æœ
        new_kws = needs.search_keywords
        if new_kws:
            raw_2 = search_by_keywords(new_kws)
            # åˆå¹¶ç»“æœ (å»é‡)
            seen = {c.get("full_name") for c in candidates_pool}
            for r in raw_2:
                if r.get("full_name") not in seen:
                    candidates_pool.append(r)
                    seen.add(r.get("full_name"))

            # é‡æ–°æ’åº (ç®€å•æŒ‰åŸæœ‰åˆ†æ•°æˆ–ç½®é¡¶æ–°ç»“æœ)
            final_pool = candidates_pool[:GATE_CANDIDATE_K]  # å†æ¬¡æˆªå–
        else:
            # æ²¡ç”Ÿæˆå…³é”®è¯ï¼Œæ— å¥ˆ Pass
            pass

    # --- Step 5: Final Judge (LLM Selection) ---
    # ç°åœ¨ final_pool é‡Œåº”è¯¥åŒ…å«äº†è¡¥æœå›æ¥çš„è¡¨
    # è¿™é‡Œè°ƒç”¨ä¹‹å‰çš„ judge é€»è¾‘åšæœ€åçš„æ¸…æ´—
    # judge_res = llm_judge(req.query, final_pool) ...

    # (ä¸ºäº†æ¼”ç¤ºï¼Œç›´æ¥è¿”å› final_pool)
    return {
        "trace_id": trace_id,
        "success": True,
        "retrieval": {
            "latency_ms": int((time.time() - t0) * 1000),
            "gate_result": gate_result,
            "needs": needs.dict(),
            "candidates": final_pool[:req.topk]
        }
    }